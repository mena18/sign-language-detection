{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    \"أ\",\n",
    "    \"ب\",\n",
    "    \"ت\",\n",
    "    \"ث\",\n",
    "    \"ج\"\n",
    "]\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "h, w = 128, 128\n",
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((w, h)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "testing_model = torchvision.models.vgg16(pretrained=False)\n",
    "num_ftrs = testing_model.classifier[-1].in_features\n",
    "testing_model.classifier[-1] = nn.Linear(num_ftrs, len(actions))\n",
    "\n",
    "best_weights = torch.load(\"weights/weights_img_c5_v2.pth\")\n",
    "testing_model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, model, transformer):\n",
    "        self.model = model\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def predict(self, image):\n",
    "        image = self.transformer(image)\n",
    "        image = torch.stack([image])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            res = self.model(image)\n",
    "            best_res = res.argmax()\n",
    "        \n",
    "        return best_res.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import operator\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "import mediapipe as mp\n",
    "\n",
    "class LettersPredictor:\n",
    "    def __init__(self, predictor, actions):\n",
    "        self.predictor = predictor\n",
    "        self.actions = actions\n",
    "        self.letters = []\n",
    "        self.predictions = []\n",
    "        self.words = []\n",
    "        self.predictions_count = dict()\n",
    "        self.hands = mp.solutions.hands.Hands(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=1)\n",
    "\n",
    "    def predict(self, frame):\n",
    "        if self.considered_frame(frame):\n",
    "            sign_idx = self.predictor.predict(Image.fromarray(frame))\n",
    "            if sign_idx in self.predictions_count:\n",
    "                self.predictions_count[sign_idx] += 1\n",
    "            else:\n",
    "                self.predictions_count[sign_idx] = 0\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def considered_frame(self, frame):\n",
    "        image = frame.copy()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = self.hands.process(image)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        if results.multi_hand_landmarks is None:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def compine_letters(self):\n",
    "        word = \"\"\n",
    "        for letter in self.letters:\n",
    "            word += letter\n",
    "        if len(word) > 0:\n",
    "            word = arabic_reshaper.reshape(word)\n",
    "            word = get_display(word) \n",
    "            self.words.append(word)\n",
    "            \n",
    "        self.letters.clear()\n",
    "        self.predictions_count.clear()\n",
    "        return self.words, word\n",
    "    \n",
    "    def predict_letter(self):\n",
    "        if len(self.predictions_count) > 0:\n",
    "                sign_idx = max(self.predictions_count.items(), key=operator.itemgetter(1))[0]\n",
    "                self.predictions.append(sign_idx)\n",
    "                self.predictions = self.predictions[-16:]\n",
    "        if len(self.predictions_count) > 0 and np.unique(self.predictions[-2:])[0] == sign_idx:\n",
    "            if len(self.letters) > 0 and self.actions[sign_idx] != self.letters[-1]:\n",
    "                self.letters.append(self.actions[sign_idx])\n",
    "            else:\n",
    "                self.letters.append(self.actions[sign_idx])\n",
    "        elif len(self.predictions_count) > 0:\n",
    "            self.letters.append(self.actions[sign_idx])        \n",
    "        self.predictions_count.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import cv2\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "predictor = Predictor(testing_model, transformer)\n",
    "letters_predictor = LettersPredictor(predictor, actions)\n",
    "\n",
    "fontpath = \"arial.ttf\" # <== https://www.freefontspro.com/14454/arial.ttf\n",
    "font = ImageFont.truetype(fontpath, 32)\n",
    "\n",
    "counter = 0\n",
    "discarded_frames = 0\n",
    "words = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    flag = letters_predictor.predict(frame)\n",
    "    \n",
    "    if flag:\n",
    "        counter += 1\n",
    "        discarded_frames = 0\n",
    "    else:\n",
    "        discarded_frames += 1\n",
    "\n",
    "    if discarded_frames == 6:\n",
    "        discarded_frames = 0\n",
    "        counter = 0\n",
    "        words, word = letters_predictor.compine_letters()\n",
    "    \n",
    "    if counter == 16:\n",
    "        counter = 0\n",
    "        letters_predictor.predict_letter()\n",
    "    \n",
    "    cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "\n",
    "    img_pil = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw.text((0, 0), ' '.join(reversed(words)), font = font)\n",
    "    frame = np.array(img_pil)\n",
    "    \n",
    "    cv2.putText(frame, \"Predict One Letter: \" + str(counter), (0, 85+1*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 250, 150), 2, cv2.LINE_8)\n",
    "    cv2.putText(frame, \"Compine Letters: \" + str(discarded_frames), (0, 85+2*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 250, 150), 2, cv2.LINE_8)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(50) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5442513ba35897157162e772485767663a309d0b481473f29ae9b3d4e5ea1118"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('slr_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
