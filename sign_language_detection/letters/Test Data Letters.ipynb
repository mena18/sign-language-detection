{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcb7bbc",
   "metadata": {},
   "source": [
    "# 1 - Check images in directory\n",
    "\n",
    "- this is responsible for checking all images in one directory by viewing whether there box around images or not using one directory \n",
    "- it will do nothing with the data but it helpful for us to count the number of useful images and check them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c888ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 13:45:22.678704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-04-14 13:45:22.678728: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f10af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(\"..\",\"..\",\"data\",\"letters\",\"all_letters_2\")\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7632cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dic = {\n",
    "    \"aleff\": 0, #أ\n",
    "    \"bb\": 1,    #ب\n",
    "    \"taa\": 2,   #ت\n",
    "    \"thaa\": 3,  #ث\n",
    "    \"jeem\": 4,  #ج\n",
    "    \"haa\": 5,   #ح\n",
    "    \"khaa\": 6,  #خ\n",
    "    \"dal\": 7,   #د\n",
    "    \"thal\": 8,  #ذ\n",
    "    \"ra\": 9,    #ر\n",
    "    \"zay\": 10,  #ز\n",
    "    \"seen\": 11, #س\n",
    "    \"sheen\": 12,    #ش\n",
    "    \"saad\": 13, #ص\n",
    "    \"dhad\": 14, #ض\n",
    "    \"ta\": 15,   #ط\n",
    "    \"dha\": 16,  #ظ\n",
    "    \"ain\": 17,  #ع\n",
    "    \"ghain\": 18,    #غ\n",
    "    \"fa\": 19,   #ف\n",
    "    \"gaaf\": 20, #ق\n",
    "    \"kaaf\": 21, #ك\n",
    "    \"laam\": 22, #ل\n",
    "    \"meem\": 23, #م\n",
    "    \"nun\": 24,  #ن\n",
    "    \"ha\": 25,   #هـ\n",
    "    \"waw\": 26,  #و\n",
    "    \"ya\": 27,   #ئ\n",
    "    \"toot\": 28, #ة\n",
    "    \"al\": 29,   #ال\n",
    "    \"la\": 30,   #لا\n",
    "    \"yaa\": 31   #ي\n",
    "}\n",
    "\n",
    "def mediapipe_detection(image,model):\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n",
    "\n",
    "\n",
    "    \n",
    "def draw_styled_landmarks(image,results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    \n",
    "\n",
    "\n",
    "def diff(pose,hand):\n",
    "    pose_x,pose_y = pose[0].x,pose[0].y\n",
    "    hand_x,hand_y = hand[0].x,hand[0].y\n",
    "    \n",
    "    return abs(pose_y-hand_y)\n",
    "    #return abs(pose_x-hand_x) + abs(pose_y-hand_y)\n",
    "\n",
    "    \n",
    "    \n",
    "def draw_rect(frame,lis):\n",
    "    min_x = 1000000\n",
    "    max_x=0\n",
    "    min_y=1000000\n",
    "    max_y=0\n",
    "    \n",
    "    for point in lis:\n",
    "        landmark_px = mp_drawing._normalized_to_pixel_coordinates(point.x, point.y,\n",
    "                                                   frame.shape[1], frame.shape[0])\n",
    "        \n",
    "\n",
    "        \n",
    "        if landmark_px:\n",
    "\n",
    "            min_x = min(landmark_px[0],min_x)\n",
    "            min_y = min(landmark_px[1],min_y)\n",
    "            max_x = max(landmark_px[0],max_x)\n",
    "            max_y = max(landmark_px[1],max_y)\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    \n",
    "    Shift_X = frame.shape[1]//50\n",
    "    Shift_Y = frame.shape[0]//50\n",
    "    \n",
    "    min_x = max(0,min_x-Shift_X)\n",
    "    min_y = max(0,min_y-Shift_Y)\n",
    "    max_x = min(frame.shape[0],max_x+Shift_X)\n",
    "    max_y = min(frame.shape[1],max_y+Shift_Y)\n",
    "    \n",
    "    cv2.rectangle(frame,(min_x,min_y),(max_x,max_y),(255,0,0),10)\n",
    "\n",
    "    return True\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1fa00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right', 'left']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = os.listdir(dir_path)[0]\n",
    "os.listdir(os.path.join(dir_path,one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59eb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image num 0\n",
      "image num 1\n",
      "image num 2\n",
      "image num 3\n",
      "image num 4\n",
      "image num 5\n",
      "image num 6\n",
      "image num 7\n",
      "image num 8\n",
      "image num 9\n",
      "image num 10\n",
      "image num 11\n",
      "image num 12\n",
      "image num 13\n",
      "image num 14\n",
      "image num 15\n",
      "image num 16\n",
      "image num 17\n",
      "image num 18\n",
      "image num 19\n",
      "image num 20\n",
      "image num 21\n",
      "image num 22\n",
      "image num 23\n",
      "image num 24\n",
      "image num 25\n",
      "image num 26\n",
      "image num 27\n",
      "image num 28\n",
      "image num 29\n",
      "image num 30\n",
      "image num 31\n",
      "image num 32\n",
      "image num 33\n",
      "image num 34\n",
      "image num 35\n",
      "image num 36\n",
      "image num 37\n",
      "image num 38\n",
      "image num 39\n"
     ]
    }
   ],
   "source": [
    "letters = os.listdir(dir_path)\n",
    "ending = False\n",
    "for letter in letters[10:]:\n",
    "    \n",
    "\n",
    "    images = os.listdir(os.path.join(dir_path,letter,\"right\"))\n",
    "\n",
    "    right_hand = []\n",
    "    left_hand = []\n",
    "    both_hands = []\n",
    "    non_hands = []\n",
    "\n",
    "\n",
    "    def add_left(frame,keypoints):\n",
    "        condition = draw_rect(frame,keypoints.left_hand_landmarks.landmark)\n",
    "        if condition:\n",
    "            left_hand.append(frame)\n",
    "        else:\n",
    "            non_hands.append(frame)\n",
    "\n",
    "    def add_right(frame,keypoints):\n",
    "        condition = draw_rect(frame,keypoints.right_hand_landmarks.landmark)\n",
    "        if condition:\n",
    "            right_hand.append(frame)\n",
    "        else:\n",
    "            non_hands.append(frame)\n",
    "\n",
    "\n",
    "\n",
    "    for i,image in enumerate(images):\n",
    "        print(\"image num\",i)\n",
    "\n",
    "        frame = cv2.imread(os.path.join(dir_path,letter,'right',image))\n",
    "\n",
    "\n",
    "        # frame  = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "        frame,results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "        draw_styled_landmarks(frame,results)\n",
    "\n",
    "        valid_left =  results.left_hand_landmarks\n",
    "        valid_right = results.right_hand_landmarks\n",
    "\n",
    "        if valid_right and valid_left:\n",
    "            left_diff = diff(results.pose_landmarks.landmark,results.left_hand_landmarks.landmark)\n",
    "            right_diff = diff(results.pose_landmarks.landmark,results.right_hand_landmarks.landmark)\n",
    "            if left_diff < right_diff:\n",
    "                add_left(frame,results)\n",
    "            else:\n",
    "                add_right(frame,results)\n",
    "        elif valid_right:\n",
    "            add_right(frame,results)\n",
    "        elif valid_left:\n",
    "            add_left(frame,results)\n",
    "        else:\n",
    "            non_hands.append(frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            ending = True\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (640, 480)) \n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    if ending:\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11905bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_hand[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f26896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71a19317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 35, 6, 75)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right_hand),len(left_hand),len(non_hands),len(left_hand) + len(right_hand) + len(non_hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8094f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in right_hand:\n",
    "    \n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 480)) \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4acf4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in left_hand:\n",
    "    \n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 480)) \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1285762",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in non_hands:\n",
    "    \n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 480)) \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c64423",
   "metadata": {},
   "source": [
    "# 2 - get keypoints from Directory\n",
    "\n",
    "- it does exactly as the name suggests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf1ea116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "16dce9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n",
    "\n",
    "        \n",
    "    \n",
    "def extract_keypoints(results,status='l'):\n",
    "    if status == 'l':\n",
    "        return np.array([ [res.x,res.y] for res in results.left_hand_landmarks.landmark ]).flatten()\n",
    "    else:\n",
    "        return np.array([ [res.x,res.y] for res in results.right_hand_landmarks.landmark ]).flatten()\n",
    "    \n",
    "                \n",
    "\n",
    "def diff(pose,hand):\n",
    "    pose_x,pose_y = pose[0].x,pose[0].y\n",
    "    hand_x,hand_y = hand[0].x,hand[0].y\n",
    "    \n",
    "    return abs(pose_y-hand_y)\n",
    "    #return abs(pose_x-hand_x) + abs(pose_y-hand_y)\n",
    "\n",
    "\n",
    "    \n",
    "def validate_hand(frame,lis):\n",
    "    \n",
    "    for point in lis:\n",
    "        landmark_px = mp_drawing._normalized_to_pixel_coordinates(point.x, point.y,\n",
    "                                                   frame.shape[1], frame.shape[0])\n",
    "        if not landmark_px:\n",
    "            return False\n",
    "\n",
    "\n",
    "    return True\n",
    "\n",
    "    \n",
    "def add_left(data,frames,frame,results):\n",
    "    condition = validate_hand(frame,results.left_hand_landmarks.landmark)\n",
    "    if condition:\n",
    "        data.append(extract_keypoints(results,'l'))\n",
    "        frames.append(frame)\n",
    "        \n",
    "        \n",
    "\n",
    "def add_right(data,frames,frame,results):\n",
    "    condition = validate_hand(frame,results.right_hand_landmarks.landmark)\n",
    "    if condition:\n",
    "        data.append(extract_keypoints(results,'r'))\n",
    "        frames.append(frame)\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be700f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_key_points(images):\n",
    "\n",
    "    data = []\n",
    "    frames = []\n",
    "\n",
    "    for i,image in enumerate(images):\n",
    "        print(\"image num\",i)\n",
    "\n",
    "        frame = cv2.imread(os.path.join(dir_path,image))\n",
    "\n",
    "\n",
    "        frame,results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "\n",
    "        valid_left =  results.left_hand_landmarks\n",
    "        valid_right = results.right_hand_landmarks\n",
    "\n",
    "        if valid_right and valid_left:\n",
    "            left_diff = diff(results.pose_landmarks.landmark,results.left_hand_landmarks.landmark)\n",
    "            right_diff = diff(results.pose_landmarks.landmark,results.right_hand_landmarks.landmark)\n",
    "            if left_diff < right_diff:\n",
    "                add_left(data,frames,frame,results)\n",
    "            else:\n",
    "                add_right(data,frames,frame,results)\n",
    "        elif valid_right:\n",
    "            add_right(data,frames,frame,results)\n",
    "        elif valid_left:\n",
    "            add_left(data,frames,frame,results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (640, 480)) \n",
    "        cv2.imshow(\"frame\",frame)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return data,frames\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c97e87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image num 0\n",
      "image num 1\n",
      "image num 2\n",
      "image num 3\n",
      "image num 4\n",
      "image num 5\n",
      "image num 6\n",
      "image num 7\n",
      "image num 8\n",
      "image num 9\n",
      "image num 10\n",
      "image num 11\n",
      "image num 12\n",
      "image num 13\n",
      "image num 14\n",
      "image num 15\n",
      "image num 16\n",
      "image num 17\n",
      "image num 18\n",
      "image num 19\n",
      "image num 20\n",
      "image num 21\n",
      "image num 22\n",
      "image num 23\n",
      "image num 24\n",
      "image num 25\n",
      "image num 26\n",
      "image num 27\n",
      "image num 28\n",
      "image num 29\n",
      "image num 30\n",
      "image num 31\n",
      "image num 32\n",
      "image num 33\n",
      "image num 34\n",
      "image num 35\n",
      "image num 36\n",
      "image num 37\n",
      "image num 38\n",
      "image num 39\n",
      "image num 40\n",
      "image num 41\n",
      "image num 42\n",
      "image num 43\n",
      "image num 44\n",
      "image num 45\n",
      "image num 46\n",
      "image num 47\n",
      "image num 48\n",
      "image num 49\n",
      "image num 50\n",
      "image num 51\n",
      "image num 52\n",
      "image num 53\n",
      "image num 54\n",
      "image num 55\n",
      "image num 56\n",
      "image num 57\n",
      "image num 58\n",
      "image num 59\n",
      "image num 60\n",
      "image num 61\n",
      "image num 62\n",
      "image num 63\n",
      "image num 64\n",
      "image num 65\n",
      "image num 66\n",
      "image num 67\n",
      "image num 68\n",
      "image num 69\n",
      "image num 70\n",
      "image num 71\n",
      "image num 72\n",
      "image num 73\n",
      "image num 74\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(\"..\",\"..\",\"data\",\"data_letter_khaa\")\n",
    "images = os.listdir(dir_path)\n",
    "\n",
    "data,frames = get_key_points(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b7658382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data),len(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828a8b3",
   "metadata": {},
   "source": [
    "# 3 - Test the keypoints from images\n",
    "\n",
    "- after we got the keypoints from the frame if we are feeling that those keypoints might be wrong we can use the below code to draw the extracted keypoints with the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7becbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_from_array(image,keyPoints):\n",
    "    image_rows, image_cols, _ = image.shape\n",
    "    \n",
    "    \n",
    "    for i in range(len(keyPoints)//2):\n",
    "        x = keyPoints[i*2]\n",
    "        y = keyPoints[i*2+1]\n",
    "        if(x!=0 and y!=0): \n",
    "            landmark_px = mp_drawing._normalized_to_pixel_coordinates(x,y,\n",
    "                                                       image_cols, image_rows)\n",
    "            cv2.circle(image, landmark_px, 2, (0,0,255),\n",
    "                     30)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca38a4b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image num 0\n",
      "image num 1\n",
      "image num 2\n",
      "image num 3\n",
      "image num 4\n",
      "image num 5\n",
      "image num 6\n",
      "image num 7\n",
      "image num 8\n",
      "image num 9\n",
      "image num 10\n",
      "image num 11\n",
      "image num 12\n",
      "image num 13\n",
      "image num 14\n",
      "image num 15\n",
      "image num 16\n",
      "image num 17\n",
      "image num 18\n",
      "image num 19\n",
      "image num 20\n",
      "image num 21\n",
      "image num 22\n",
      "image num 23\n",
      "image num 24\n",
      "image num 25\n",
      "image num 26\n",
      "image num 27\n",
      "image num 28\n",
      "image num 29\n",
      "image num 30\n",
      "image num 31\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    \n",
    "    print(f\"image num {i}\")\n",
    "    image = frames[i]\n",
    "    keypoint = data[i]\n",
    "\n",
    "    draw_landmark_from_array(image,keypoint)\n",
    "\n",
    "    image = cv2.resize(image, (640, 480)) \n",
    "    cv2.imshow(\"frame\",image)\n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3309de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
